#!/usr/bin/env python3
__author__ = "Jan Balewski"
__email__ = "janstar1122@gmail.com"

'''
Jan:
give my python code using only numpy and COBYLA which reads in iris data set, constructs ML classifier consisting of 3 layers of fully connected network  4-5-3. The last layer should represent the 2 classes which encode 3 types of iris binary.

 COBYLA should be used as minimizer
Use cross-entropy loss
Print loss vs. iteration at the end

Please change the logic. make the last layer to have 2 cells. Use sigmoid activation for the last layer.  Map 2 output floats as 1 bits. Interprte thos 2 bits as binary encoding of the label. Construct loss approariatly to match this binary encoding

Code below is partially generated by ChatGPT4

Output:


'''
import numpy as np
from scipy.optimize import minimize
from sklearn import datasets
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split


# Function to encode labels as 2-bit binary
#...!...!....................
def binary_encode_labels(labels):
    # Binary encoding: 00, 01, 10
    binary_encoded = np.array([[0, 0], [0, 1], [1, 0]])[labels]
    return binary_encoded


# Activation functions and forward pass
#...!...!....................
def sigmoid(x):
    return 1 / (1 + np.exp(-x))

#...!...!....................
def forward_pass(X, params):
    W1 = params[:end_W1].reshape(input_size, hidden_size)
    b1 = params[end_W1:end_b1]
    W2 = params[end_b1:end_W2].reshape(hidden_size, output_size)
    b2 = params[end_W2:]

    Z1 = np.dot(X, W1) + b1
    A1 = sigmoid(Z1)
    Z2 = np.dot(A1, W2) + b2
    A2 = sigmoid(Z2)  # Sigmoid output for binary encoding
    return A2

# Binary cross-entropy loss function
#...!...!....................
def binary_cross_entropy_loss(Y_pred, Y_true):
    #print('BCEL:',Y_pred.shape, Y_true.shape)
    #print('few vals Y_pred:',Y_pred[:5],'\nYtrue:',Y_true[:5]); aaa
    return -np.mean(Y_true * np.log(Y_pred + 1e-9) + (1 - Y_true) * np.log(1 - Y_pred + 1e-9))

# Loss function including biases
#...!...!....................
def loss_function(params, X, Y): 
    Y_pred = forward_pass(X, params)
    loss=binary_cross_entropy_loss(Y_pred, Y)
    loss_history.append(loss)
    return loss

# Convert binary predictions back to class labels
#...!...!....................
def binary_to_label(binary_array):
    return np.array([2 if row[0] == 1 else row[1] for row in binary_array])


#...!...!....................
def normalize_input_data(X):
    # The standard score of a sample x is calculated as:  z = (x - u) / s
    scaler = StandardScaler()
    Z = scaler.fit_transform(X)
    print('NID end: Z shape:',Z.shape)
    
    if 1:
        blowFact=2
        print('NID add atan transform, blowFact=',blowFact)
        Z=np.arctan(blowFact*Z) *2/np.pi

    print_range(Z,'inp norm')
    return Z

#...!...!....................
def print_range(Z,text):
    print('\ndata range (%s)  shape:'%text,Z.shape)
    print('mean :',np.mean(Z,axis=0))
    print('std  :',np.std(Z,axis=0))
    print('min  :',np.min(Z,axis=0))
    print('max  :',np.max(Z,axis=0))

#=================================
#=================================
#  M A I N 
#=================================
#=================================
if __name__ == "__main__":
    np.set_printoptions(precision=3)
    # Load and preprocess the Iris dataset
    iris = datasets.load_iris()
    X = iris.data
    y = iris.target

    # Neural network parameters
    input_size = X.shape[1]
    hidden_size = 2
    output_size = 2  # Two output neurons for binary encoding
    mxIter=450 # for COBYLA
    rnd_seed=42 # for reproducibility of data split


    X_scaled =normalize_input_data(X)
   
    # Binary encode the labels
    y_binary_encoded = binary_encode_labels(y)

    X_train, X_test, y_train, y_test = train_test_split(X_scaled, y_binary_encoded, test_size=0.2, random_state=rnd_seed)

    # Initialize weights and biases, uniform distribution over [0, 1).
    #1np.random.seed(rnd_seed)
    W1 = np.random.rand(input_size, hidden_size)
    b1 = np.random.rand(hidden_size)
    W2 = np.random.rand(hidden_size, output_size)
    b2 = np.random.rand(output_size)

    # Flatten weights and biases for optimization
    initial_params = np.hstack((W1.ravel(), b1, W2.ravel(), b2))

    # Define the end indices for each set of parameters
    end_W1 = input_size * hidden_size
    end_b1 = end_W1 + hidden_size
    end_W2 = end_b1 + hidden_size * output_size

 
    # Loss history
    loss_history = []

    # Use COBYLA optimizer
    result = minimize(fun=loss_function, 
                      x0=initial_params, 
                      args=(X_train, y_train), 
                      method='COBYLA',
                      options={'maxiter': mxIter,'rhobeg': 0.8})

    # Print loss history
    print("\nLoss History (Iteration vs. Loss):")
    for j, loss in enumerate(loss_history):
        if j%50==0 or j==mxIter-1:
            print(f"Iteration {j + 1}: Loss = {loss:.3f}")

    # Extract the optimized weights
    weightsOpt = result.x
    wMin=min(weightsOpt)
    wMax=max(weightsOpt)
    wAvr=np.mean(weightsOpt)

    print('num par=',weightsOpt.shape,'W in [%.2f,%.2f] avr=%.2f'%(wMin,wMax,wAvr))


    # Test the model
    Y_pred_test = forward_pass(X_test, weightsOpt)
    Y_pred_test_binary = (Y_pred_test > 0.5).astype(int)

    Y_pred_test_labels = binary_to_label(Y_pred_test_binary)
    y_test_labels = binary_to_label(y_test)

    # Calculate accuracy
    accuracy = np.mean(Y_pred_test_labels == y_test_labels)
    print(f"Accuracy: {accuracy * 100:.2f}%")

    # Compute the confusion matrix
    from sklearn.metrics import confusion_matrix
    conf_matrix = confusion_matrix(y_test_labels,Y_pred_test_labels)
    print('\nconfusion matrix, test samples:%d'%(X_test.shape[0]))
    for i,rec  in enumerate(conf_matrix):
        print('true:%d  reco:%s'%(i,rec))

    print('\nfew vals Y_pred:',Y_pred_test[:5],'\nYtrue:',y_test[:5])


'''
Jan: 
I'm very happy with your work. Now assume the input data set has K=9 labels. 
Keep the whole logic as-is., continue to use binary encoding.
Rewrite the code so it works for arbitrary K.

ChatGPT:

Those are the changes (not tested by human)

def generate_binary_encodings(num_classes):
    return np.array([list(np.binary_repr(i, width=int(np.ceil(np.log2(num_classes))))) for i in range(num_classes)], dtype=int)

def binary_encode_labels(labels, binary_encodings):
    return binary_encodings[labels]

# Example with K = 9 (or replace with any K)
K = 9
binary_encodings = generate_binary_encodings(K)

# Create a synthetic dataset with K classes (replace with your dataset)
X, y = make_classification(n_samples=1000, n_features=4, n_classes=K, n_clusters_per_class=1, random_state=42)

scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

y_binary_encoded = binary_encode_labels(y, binary_encodings)

X_train, X_test, y_train, y_test = train_test_split(X_scaled, y_binary_encoded, test_size=0.2, random_state=42)

# Neural network parameters
input_size = 4  # Depends on your dataset
hidden_size = 10  # Adjustable
output_size = binary_encodings.shape[1]  # Number of bits in binary encoding

# Activation functions and forward pass (same as before)

# Binary cross-entropy loss function (same as before)

# Initialize weights and biases (same as before)

# Flatten weights and biases for optimization (same as before)

# Define the end indices for each set of parameters (same as before)

# Loss function including biases (same as before)

# Use COBYLA optimizer (same as before)

# Extract optimized weights and biases (same as before)

# Test the model (same as before)

# Convert binary predictions back to class labels
def binary_to_label(binary_array, binary_encodings):
    binary_list = binary_array.tolist()
    return np.array([binary_encodings.tolist().index(b) for b in binary_list])

# Calculate accuracy
Y_pred_test_binary = (Y_pred_test > 0.5).astype(int)
Y_pred_test_labels = binary_to_label(Y_pred_test_binary, binary_encodings)
y_test_labels = binary_to_label(y_test, binary_encodings)
accuracy = np.mean(Y_pred_test_labels == y_test_labels)
print(f"Accuracy: {accuracy * 100:.2f}%")
'''
